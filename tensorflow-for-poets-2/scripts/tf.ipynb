{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.util import compat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(model_file):\n",
    "  graph = tf.Graph()\n",
    "  graph_def = tf.GraphDef()\n",
    "\n",
    "  with open(model_file, \"rb\") as f:\n",
    "    graph_def.ParseFromString(f.read())\n",
    "  with graph.as_default():\n",
    "    tf.import_graph_def(graph_def)\n",
    "\n",
    "  return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_file):\n",
    "  label = []\n",
    "  proto_as_ascii_lines = tf.gfile.GFile(label_file).readlines()\n",
    "  for l in proto_as_ascii_lines:\n",
    "    label.append(l.rstrip())\n",
    "  return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tensor_from_image_file(file_name, input_height=299, input_width=299,\n",
    "  input_mean=0, input_std=255):\n",
    "  input_name = \"file_reader\"\n",
    "  output_name = \"normalized\"\n",
    "  file_reader = tf.read_file(file_name, input_name)\n",
    "  if file_name.endswith(\".png\"):\n",
    "    image_reader = tf.image.decode_png(file_reader, channels = 3,\n",
    "                                       name='png_reader')\n",
    "  elif file_name.endswith(\".gif\"):\n",
    "    image_reader = tf.squeeze(tf.image.decode_gif(file_reader,\n",
    "                                                  name='gif_reader'))\n",
    "  elif file_name.endswith(\".bmp\"):\n",
    "    image_reader = tf.image.decode_bmp(file_reader, name='bmp_reader')\n",
    "  else:\n",
    "    image_reader = tf.image.decode_jpeg(file_reader, channels = 3,\n",
    "                                        name='jpeg_reader')\n",
    "  float_caster = tf.cast(image_reader, tf.float32)\n",
    "  dims_expander = tf.expand_dims(float_caster, 0);\n",
    "  resized = tf.image.resize_bilinear(dims_expander, [input_height, input_width])\n",
    "  normalized = tf.divide(tf.subtract(resized, [input_mean]), [input_std])\n",
    "  sess = tf.Session()\n",
    "  result = sess.run(normalized)\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"/home/minato/217.jpg\"\n",
    "model_file = \"../tf_files/inception_retrained_graph_new_2.pb\"\n",
    "label_file = \"../tf_files/inception_retrained_labels_new_2.txt\"\n",
    "input_height = 299\n",
    "input_width = 299\n",
    "input_mean = 128\n",
    "input_std = 128\n",
    "input_layer = \"Mul\"\n",
    "output_layer = \"final_result\"\n",
    "\n",
    "input_name = \"import/\" + input_layer\n",
    "output_name = \"import/\" + output_layer\n",
    "graph = load_graph(model_file)\n",
    "input_operation = graph.get_operation_by_name(input_name);\n",
    "output_operation = graph.get_operation_by_name(output_name);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.6534995e-04 9.7111352e-02 6.7729540e-03 1.2051094e-03 7.1189759e-05\n",
      " 1.0385051e-03 3.6110898e-04 1.0445697e-03 5.1032235e-05 4.3704110e-04\n",
      " 3.7048522e-02 6.0789072e-04 8.5274613e-01 4.5428157e-04 3.6363071e-04\n",
      " 4.2129910e-04]\n",
      "\n",
      "Evaluation time (1-image): 0.516s\n",
      "\n",
      "point shoot digital cameras 0.8527461\n",
      "accessory kits 0.09711135\n",
      "memory 0.037048522\n",
      "camera batteries 0.006772954\n",
      "computers accessories 0.0012051094\n"
     ]
    }
   ],
   "source": [
    "t = read_tensor_from_image_file(file_name,\n",
    "                              input_height=input_height,\n",
    "                              input_width=input_width,\n",
    "                              input_mean=input_mean,\n",
    "                              input_std=input_std)\n",
    "\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "  start = time.time()\n",
    "  results = sess.run(output_operation.outputs[0],\n",
    "                  {input_operation.outputs[0]: t})\n",
    "  end=time.time()\n",
    "\n",
    "results = np.squeeze(results)\n",
    "print(results)\n",
    "top_k = results.argsort()[-5:][::-1]\n",
    "labels = load_labels(label_file)\n",
    "\n",
    "print('\\nEvaluation time (1-image): {:.3f}s\\n'.format(end-start))\n",
    "\n",
    "for i in top_k:\n",
    "    print(labels[i], results[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected int32, got array([[[[0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         ...,\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375]],\n\n        [[0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         ...,\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375]],\n\n        [[0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         ...,\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375]],\n\n        ...,\n\n        [[0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         ...,\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375]],\n\n        [[0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         ...,\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375]],\n\n        [[0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         ...,\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375]]]], dtype=float32) of type 'ndarray' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-3faa74cc95b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m                                   \u001b[0minput_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                                   input_std=input_std)\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dlcv/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1094\u001b[0m       ops.convert_to_tensor(\n\u001b[1;32m   1095\u001b[0m           \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"concat_dim\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m           \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m               tensor_shape.scalar())\n\u001b[1;32m   1098\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dlcv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dlcv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dlcv/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    227\u001b[0m                                          as_ref=False):\n\u001b[1;32m    228\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dlcv/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    206\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m    207\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 208\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    209\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m~/.virtualenvs/dlcv/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    381\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m       \u001b[0m_AssertCompatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m       \u001b[0;31m# check to them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dlcv/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m_AssertCompatible\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m       raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n\u001b[0;32m--> 303\u001b[0;31m                       (dtype.name, repr(mismatch), type(mismatch).__name__))\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected int32, got array([[[[0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         ...,\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375]],\n\n        [[0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         ...,\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375]],\n\n        [[0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         ...,\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375]],\n\n        ...,\n\n        [[0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         ...,\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375]],\n\n        [[0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         ...,\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375]],\n\n        [[0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         ...,\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375],\n         [0.984375, 0.984375, 0.984375]]]], dtype=float32) of type 'ndarray' instead."
     ]
    }
   ],
   "source": [
    "import os\n",
    "count = 0\n",
    "for root, directories, filenames in os.walk('/home/minato/datasets_new/'):\n",
    "    t1 = None\n",
    "    arr = []    \n",
    "    for filename in filenames:\n",
    "        count = count + 1\n",
    "        file_name=os.path.join(root,filename)\n",
    "        if(count==1):\n",
    "            t1 = read_tensor_from_image_file(file_name,\n",
    "                                  input_height=input_height,\n",
    "                                  input_width=input_width,\n",
    "                                  input_mean=input_mean,\n",
    "                                  input_std=input_std)\n",
    "            arr = [t1]\n",
    "        else:\n",
    "            t1 = read_tensor_from_image_file(file_name,\n",
    "                                  input_height=input_height,\n",
    "                                  input_width=input_width,\n",
    "                                  input_mean=input_mean,\n",
    "                                  input_std=input_std)\n",
    "            arr = tf.concat(arr, [t1])\n",
    "            \n",
    "    tf.shape(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        with tf.Session(graph=graph) as sess:\n",
    "            start = time.time()\n",
    "            results = sess.run(output_operation.outputs[0],\n",
    "                          {input_operation.outputs[0]: t})\n",
    "            end=time.time()\n",
    "\n",
    "        results = np.squeeze(results)\n",
    "        print(results)\n",
    "        top_k = results.argsort()[-5:][::-1]\n",
    "        labels = load_labels(label_file)\n",
    "\n",
    "        print('\\nEvaluation time (1-image): {:.3f}s\\n'.format(end-start))\n",
    "\n",
    "        for i in top_k:\n",
    "            print(labels[i], results[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
